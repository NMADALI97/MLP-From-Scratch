{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP-from-Scratch2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G7GR5zFhJjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfihlsOQhfem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip t*-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhYzJFhWgdRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O92FJCSDhNVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.join(os.path.expanduser('~'), 'Documents', 'OR 610')\n",
        "def read_idx(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
        "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
        "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
        "    \n",
        "def oneHotEncoding(label):\n",
        "    n = np.max(label)+1\n",
        "    v = np.eye(n)[label]\n",
        "    return v.T\n",
        "\n",
        "\n",
        "def imageProcess(data):\n",
        "    data = data/255\n",
        "    data = data.reshape(data.shape[0],data.shape[1]*data.shape[2])\n",
        "    return data.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcI5sQaiggkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softMax(X):\n",
        "    e = np.exp(X)\n",
        "    p = e/np.sum(e, axis=0)\n",
        "    return p\n",
        "\n",
        "def ReLU(z):\n",
        "    return np.maximum(0,z)\n",
        "def sigmoid(z):\n",
        "    return 1./(1.+np.exp(-z))\n",
        "def tanh(z):\n",
        "    return np.tanh(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K446hRTlgmlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dReLU(z):\n",
        "    return (z > 0) * 1\n",
        "def dSigmoid(z):\n",
        "    return sigmoid(z) *(1-sigmoid (z))\n",
        "def dTanh(z):\n",
        "    return 1/(np.cosh(z)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxpQbQ-ggrnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossEntropyR2(y, y_hat, lamda, params):\n",
        "    m = y.shape[1]\n",
        "    s=0\n",
        "    for i in range(len(params)//2):\n",
        "      s+=np.sum(params['W'+str(i+1)]**2)\n",
        "   \n",
        "    cost = -(1/m) * np.sum(y*np.log(y_hat)) + lamda/(2*m) * (s)\n",
        "    \n",
        "    return cost\n",
        "\n",
        "\n",
        "def forward(X,params,activation):\n",
        "    n_layers=len(params)//2\n",
        "    forwardPass = {}\n",
        "   \n",
        "    forwardPass['Z1'] = np.matmul(params['W1'], X) + params['b1']\n",
        "    forwardPass['A1'] = activation(forwardPass['Z1'])\n",
        "\n",
        "    for i in range(1,n_layers):\n",
        "        forwardPass['Z'+str(i+1)] = np.matmul(params['W'+str(i+1)], forwardPass['A'+str(i)]) + params['b'+str(i+1)]\n",
        "        forwardPass['A'+str(i+1)] = activation(forwardPass['Z'+str(i+1)])\n",
        "    return forwardPass\n",
        "\n",
        "\n",
        "def back(X, y,forwardPass, params,dActivation):\n",
        "    m = X.shape[1]\n",
        "    gradient = {}\n",
        "    n_layers=len(params)//2\n",
        "\n",
        "    gradient['dZ'+str(n_layers)] = forwardPass['A'+str(n_layers)] - y\n",
        "\n",
        "    gradient['dW'+str(n_layers)] = (1./m) * np.matmul(gradient['dZ'+str(n_layers)], forwardPass['A'+str(n_layers-1)].T)\n",
        "\n",
        "    gradient['db'+str(n_layers)] = (1./m) * np.sum(gradient['dZ'+str(n_layers)], axis=1, keepdims=True)\n",
        "   \n",
        "    for i in reversed(range(1,n_layers-1)):\n",
        "      gradient['dA'+str((i+1))] = np.matmul(params['W'+str((i+1)+1)].T, gradient['dZ'+str((i+1)+1)])\n",
        "      gradient['dZ'+str((i+1))] = gradient['dA'+str((i+1))] * dActivation(forwardPass['Z'+str((i+1))])\n",
        "      gradient['dW'+str((i+1))] = (1./m) * np.matmul(gradient['dZ'+str((i+1))], forwardPass['A'+str(i)].T)\n",
        "      gradient['db'+str((i+1))] = (1./m) * np.sum(gradient['dZ'+str((i+1))])\n",
        "    i=0\n",
        "    gradient['dA'+str((i+1))] = np.matmul(params['W'+str((i+1)+1)].T, gradient['dZ'+str((i+1)+1)])\n",
        "    gradient['dZ'+str((i+1))] = gradient['dA'+str((i+1))] * dActivation(forwardPass['Z'+str((i+1))])\n",
        "    gradient['dW'+str((i+1))] = (1./m) * np.matmul(gradient['dZ'+str((i+1))], X.T)\n",
        "    gradient['db'+str((i+1))] = (1./m) * np.sum(gradient['dZ'+str((i+1))])\n",
        "    return gradient\n",
        "\n",
        "def updater(params,grad,eta,lamda,m):\n",
        "    updatedParams = {}\n",
        "    n_layers=len(params)//2\n",
        "    for i in range(n_layers):\n",
        "      updatedParams['W'+str((i+1))] = params['W'+str((i+1))] - eta * grad['dW'+str((i+1))] - (params['W'+str((i+1))]*lamda*eta)/m\n",
        "      updatedParams['b'+str((i+1))] = params['b'+str((i+1))] - eta * grad['db'+str((i+1))]\n",
        "\n",
        "    return updatedParams\n",
        "\n",
        "def classifer(X, params,activation):\n",
        "    n_layers=len(params)//2\n",
        "    for i in reversed(n_layers-1):\n",
        "      Z = np.matmul(params['W'+str(i+1)], X) + params['b'+str(i+1)]\n",
        "      A = activation(Z)\n",
        "\n",
        "    Z = np.matmul(params['W'+str(n_layers)],A) + params['b'+str(n_layers)]\n",
        "    A = softMax(Z)\n",
        "    pred = np.argmax(A, axis=0)\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsYWFlQQg6bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "044cc9aa-cdfa-45a8-d6fe-2bb96bbe1206"
      },
      "source": [
        "X_train = imageProcess(read_idx('train-images-idx3-ubyte'))\n",
        "y_train = oneHotEncoding(read_idx('train-labels-idx1-ubyte'))\n",
        "X_test = imageProcess(read_idx('t10k-images-idx3-ubyte'))\n",
        "y_test = read_idx('t10k-labels-idx1-ubyte')\n",
        "\n",
        "#### General Hyperparameters\n",
        "m=10000 #batch size\n",
        "n_x = X_train.shape[0]\n",
        "n_h = 100\n",
        "eta = 1\n",
        "lamda = 2\n",
        "np.random.seed(7)\n",
        "epoch = 1000"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyIQLB1Tg8M8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#m = X_train.shape[1]\n",
        "#Initializing weightss\n",
        "sigmoidParams = {'W1': np.random.randn(n_h, n_x)* np.sqrt(1. / n_x),\n",
        "                 'b1': np.zeros((n_h, 1)),\n",
        "                 'W2': np.random.randn(10, n_h)* np.sqrt(1. / n_h),\n",
        "                 'b2': np.zeros((10, 1))\n",
        "                 }\n",
        "\n",
        "start = datetime.now()\n",
        "for i in range(epoch):\n",
        "    print(i)\n",
        "    #shuffle batch index\n",
        "    idx = np.random.permutation(X_train.shape[1])[:m]\n",
        "    X=X_train[:,idx]\n",
        "    y=y_train[:,idx]\n",
        "    #forward pass\n",
        "    forwardPass = forward(X,sigmoidParams,sigmoid)\n",
        "    #cost\n",
        "    cost = crossEntropyR2(y, forwardPass['A2'], lamda, sigmoidParams)\n",
        "   \n",
        "    #back Prop\n",
        "    gradient = back(X, y, forwardPass, sigmoidParams,dSigmoid)\n",
        "    #updating weights\n",
        "    sigmoidParams=updater(sigmoidParams,gradient,eta,lamda,m)\n",
        "\n",
        "difference = datetime.now() - start\n",
        "print(\"Final cost:\", cost)\n",
        "print('time to train:', difference)\n",
        "\n",
        "y_hat = classifer(X_test, sigmoidParams, sigmoid)\n",
        "\n",
        "\n",
        "print('Accuracy:',sum(y_hat==y_test)*1/len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NETFA59YhAng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######RELU SECTION ############\n",
        "reluParams = {'W1': np.random.randn(n_h, n_x)* np.sqrt(2. / n_x),\n",
        "                 'b1': np.zeros((n_h, 1)),\n",
        "                 'W2': np.random.randn(10, n_h)* np.sqrt(2. / n_h),\n",
        "                 'b2': np.zeros((10, 1))\n",
        "                 }\n",
        "\n",
        "start = datetime.now()\n",
        "for i in range(epoch):\n",
        "    #shuffle batch index\n",
        "    idx = np.random.permutation(X_train.shape[1])[:m]\n",
        "    X=X_train[:,idx]\n",
        "    y=y_train[:,idx]\n",
        "    #forward pass\n",
        "    forwardPass = forward(X,reluParams,ReLU)\n",
        "    #cost\n",
        "    cost = crossEntropyR2(y, forwardPass['A2'], lamda, reluParams)\n",
        "    #back Prop\n",
        "    gradient = back(X, y, forwardPass, reluParams,dReLU)\n",
        "    #updating weights\n",
        "    reluParams=updater(reluParams,gradient,eta,lamda,m)\n",
        "difference = datetime.now() - start\n",
        "print(\"Final cost:\", cost)\n",
        "print('time to train:', difference)\n",
        "\n",
        "y_hat = classifer(X_test, reluParams, ReLU)\n",
        "\n",
        "\n",
        "print('Accuracy:',sum(y_hat==y_test)*1/len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}